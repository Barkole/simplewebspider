* Improve performance getting new links:
  - Don't use xml normalizing and parsing at all, but splitting by "="
* Building new links
  - URL normalization: http://en.wikipedia.org/wiki/URL_normalization
* HttpClient: http://hc.apache.org/httpclient-3.x/
  - Setting Browser information
  - Muli threaded mode: http://hc.apache.org/httpclient-3.x/threading.html
* Configuration
  - Provide default settings
  - allow set configuration by command -> http://commons.apache.org/cli/
  - allow set configuration by file
* More daemon like run mode
* Unit tests
* Maven plugins: http://maven.apache.org/plugins/
  - site: Page generating
  - Building easy to run assemblies: http://maven.apache.org/plugins/maven-assembly-plugin/
  - pmd http://maven.apache.org/plugins/maven-pmd-plugin/
  - scm
  - jdepend: http://mojo.codehaus.org/jdepend-maven-plugin/
  - taglist: http://mojo.codehaus.org/taglist-maven-plugin/
  - licence: http://code.google.com/p/maven-license-plugin/wiki/Configuration
  - buildnumber: http://commons.ucalgary.ca/projects/maven-buildnumber-plugin/howto.html
* Support for more performant data bases:
  - db4o: http://de.wikipedia.org/wiki/Db4o
  - hibernate
  - h2: http://www.h2database.com/html/main.html
  - Derby/JavaDB
  
Known bugs:
* Failed to handle mailto link: (low - causes no failure)
	INFO: Ignoring malformed URL "mailto:info@xxx.com.ni"
	java.lang.NullPointerException
		at simplespider.simplespider.util.SimpleUrl.<init>(SimpleUrl.java:73)
		at simplespider.simplespider.util.SimpleUrl.newURL(SimpleUrl.java:255)
		at simplespider.simplespider.bot.CrawlerImpl.saveLinks(CrawlerImpl.java:114)
		at simplespider.simplespider.bot.CrawlerImpl.crawl(CrawlerImpl.java:91)
		at simplespider.simplespider.bot.CrawlerRunner.run(CrawlerRunner.java:20)
		at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:885)
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907)
		at java.lang.Thread.run(Thread.java:619)
* Unique constrain failures: (low - causes no failure)
	WARNING: Failed to crawl
	java.lang.RuntimeException: Failed to save link Link [id:null,url:"http://www.xxx.de/xxx/xxx/",done:false]
		at simplespider.simplespider.dao.jdbc.JdbcLinkDao.save(JdbcLinkDao.java:167)
		at simplespider.simplespider.bot.CrawlerImpl.saveLinks(CrawlerImpl.java:133)
		at simplespider.simplespider.bot.CrawlerImpl.crawl(CrawlerImpl.java:91)
		at simplespider.simplespider.bot.CrawlerRunner.run(CrawlerRunner.java:20)
		at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:885)
		at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907)
		at java.lang.Thread.run(Thread.java:619)
	Caused by: java.sql.SQLException: Unique constraint violation: LINK_URL_UNIQUE in statement [INSERT INTO link (url, done, errors) VALUES (?, ?, ?)]
		at org.hsqldb.jdbc.Util.throwError(Unknown Source)
		at org.hsqldb.jdbc.jdbcPreparedStatement.executeUpdate(Unknown Source)
		at simplespider.simplespider.dao.jdbc.JdbcLinkDao.save(JdbcLinkDao.java:145)
		... 6 more
* Program quits, if to less links available (low - restarting causes rerun)
	The problem is, that main thread not wait for running thread. The could insert more new links
	-> Solution: try it after quitting of a running thread again, until no thread are running,
	   if there is no link, too, so no link will be inserted and program can quit